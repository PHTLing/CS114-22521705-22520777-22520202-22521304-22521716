{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8789399,"sourceType":"datasetVersion","datasetId":5284217}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport random\nimport os\nimport multiprocessing as mp\nimport hashlib\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras import layers, models\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:43:48.490226Z","iopub.execute_input":"2024-06-29T04:43:48.490962Z","iopub.status.idle":"2024-06-29T04:43:48.497362Z","shell.execute_reply.started":"2024-06-29T04:43:48.490930Z","shell.execute_reply":"2024-06-29T04:43:48.496314Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"SPLITS_ID = 1","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:43:56.954249Z","iopub.execute_input":"2024-06-29T04:43:56.954626Z","iopub.status.idle":"2024-06-29T04:43:56.958780Z","shell.execute_reply.started":"2024-06-29T04:43:56.954585Z","shell.execute_reply":"2024-06-29T04:43:56.957891Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"DATASET_DIR = \"/kaggle/input/motocycledataset/Data\"\nBATCH_SIZE = 64\nSEED = 42\nWIDTH = 224\nHEIGHT = 224","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:43:59.050850Z","iopub.execute_input":"2024-06-29T04:43:59.051212Z","iopub.status.idle":"2024-06-29T04:43:59.055797Z","shell.execute_reply.started":"2024-06-29T04:43:59.051184Z","shell.execute_reply":"2024-06-29T04:43:59.054857Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# DATA LOADING","metadata":{}},{"cell_type":"code","source":"train_csv_path = os.path.join(DATASET_DIR, f\"MotocycleDataset-Splits-{SPLITS_ID}-Train.csv\")\ntrain_df = pd.read_csv(train_csv_path, header=None, names=[\"file_path\", \"class\"])\ntrain_df[\"file_path\"] = train_df[\"file_path\"].apply(lambda x: os.path.join(DATASET_DIR, x))\ntrain_df[\"class\"] = train_df[\"class\"].apply(lambda x: str(x))","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:44:06.258170Z","iopub.execute_input":"2024-06-29T04:44:06.258568Z","iopub.status.idle":"2024-06-29T04:44:06.419180Z","shell.execute_reply.started":"2024-06-29T04:44:06.258537Z","shell.execute_reply":"2024-06-29T04:44:06.418437Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# PREPROCESSING","metadata":{}},{"cell_type":"code","source":"image_set = set()\nnum_duplicates = 0\nnum_errors = 0\n\ndef hash_numpy_array(arr):\n    arr_bytes = arr.tobytes()\n    hash_obj = hashlib.sha256(arr_bytes)\n    hash_hex = hash_obj.hexdigest()\n    return hash_hex\n\ndef validate_image(image_path, skip_duplicate):\n    global num_duplicates, num_errors\n    if not os.path.exists(image_path):\n        return False\n    if not os.path.isfile(image_path):\n        return False\n    try:\n        with Image.open(image_path) as img:\n            img.resize((WIDTH, HEIGHT))\n            if skip_duplicate:\n                hash_value = hash_numpy_array(np.array(img))\n                if hash_value in image_set:\n                    num_duplicates += 1\n                    return False\n                else:\n                    image_set.add(hash_value)\n        return True\n\n    except Exception as e:\n        num_errors += 1\n        return False\n        \ndef validate_images_multicore(df, num_processes, skip_duplicate=False):\n    with mp.Pool(num_processes) as pool:\n        results = pool.starmap(\n            validate_image, \n            zip(df[\"file_path\"], [skip_duplicate] * len(df))\n        )\n    return df[results]  ","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:44:18.602472Z","iopub.execute_input":"2024-06-29T04:44:18.602828Z","iopub.status.idle":"2024-06-29T04:44:18.612222Z","shell.execute_reply.started":"2024-06-29T04:44:18.602801Z","shell.execute_reply":"2024-06-29T04:44:18.611247Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"train_df = validate_images_multicore(\n    train_df, \n    num_processes=12, \n    skip_duplicate=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:44:34.135269Z","iopub.execute_input":"2024-06-29T04:44:34.136144Z","iopub.status.idle":"2024-06-29T04:49:31.152983Z","shell.execute_reply.started":"2024-06-29T04:44:34.136113Z","shell.execute_reply":"2024-06-29T04:49:31.151979Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"code","source":"# Reset\nimage_set = set()\nnum_duplicates = 0\nnum_errors = 0","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:49:31.154769Z","iopub.execute_input":"2024-06-29T04:49:31.155074Z","iopub.status.idle":"2024-06-29T04:49:31.159726Z","shell.execute_reply.started":"2024-06-29T04:49:31.155044Z","shell.execute_reply":"2024-06-29T04:49:31.158821Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING","metadata":{}},{"cell_type":"code","source":"data_generator = ImageDataGenerator(\n    rescale=1/255,\n    validation_split=0.2,\n)\n\ndataframe_config = {\n    'dataframe': train_df,\n    'x_col': 'file_path',\n    'y_col': 'class',\n    'target_size': (HEIGHT, WIDTH),\n    'batch_size': BATCH_SIZE,\n    'class_mode': 'categorical',\n    'shuffle': True,\n    'seed': SEED,\n    'color_mode': 'rgb',\n}\n\ntrain_generator = data_generator.flow_from_dataframe(**dataframe_config, subset='training')\nval_generator = data_generator.flow_from_dataframe(**dataframe_config, subset='validation')","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:49:54.784316Z","iopub.execute_input":"2024-06-29T04:49:54.784637Z","iopub.status.idle":"2024-06-29T04:50:07.130102Z","shell.execute_reply.started":"2024-06-29T04:49:54.784613Z","shell.execute_reply":"2024-06-29T04:50:07.129237Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Found 21368 validated image filenames belonging to 5 classes.\nFound 5341 validated image filenames belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetV2S\n\nbase_model = EfficientNetV2S(\n    include_top=False,  \n    weights='imagenet', \n    input_shape=(224, 224, 3) \n)\n\nmodel = models.Sequential()\nmodel.add(base_model)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(1024, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(5, activation='softmax'))  \n\nmodel.compile(\n    optimizer='adam',\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:50:07.133110Z","iopub.execute_input":"2024-06-29T04:50:07.133414Z","iopub.status.idle":"2024-06-29T04:50:11.723784Z","shell.execute_reply.started":"2024-06-29T04:50:07.133389Z","shell.execute_reply":"2024-06-29T04:50:11.722877Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/efficientnet_v2/efficientnetv2-s_notop.h5\n\u001b[1m82420632/82420632\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ efficientnetv2-s (\u001b[38;5;33mFunctional\u001b[0m)   │ ?                      │    \u001b[38;5;34m20,331,360\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ efficientnetv2-s (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)   │ ?                      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">20,331,360</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d        │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m20,331,360\u001b[0m (77.56 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,331,360</span> (77.56 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m20,177,488\u001b[0m (76.97 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,177,488</span> (76.97 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m153,872\u001b[0m (601.06 KB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">153,872</span> (601.06 KB)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"learning_rate = 0.001\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:50:11.725045Z","iopub.execute_input":"2024-06-29T04:50:11.725422Z","iopub.status.idle":"2024-06-29T04:50:11.729698Z","shell.execute_reply.started":"2024-06-29T04:50:11.725367Z","shell.execute_reply":"2024-06-29T04:50:11.728830Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator, \n    epochs=epochs,\n    validation_data = val_generator\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T04:50:11.730817Z","iopub.execute_input":"2024-06-29T04:50:11.731148Z","iopub.status.idle":"2024-06-29T05:44:14.994926Z","shell.execute_reply.started":"2024-06-29T04:50:11.731118Z","shell.execute_reply":"2024-06-29T05:44:14.994093Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n/opt/conda/lib/python3.10/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1719636848.173839     234 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1719636848.406160     234 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 37/334\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:19\u001b[0m 673ms/step - accuracy: 0.3379 - loss: 1.4886","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719637020.091191     233 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.5081 - loss: 1.1713","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719637231.094646     234 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m687s\u001b[0m 1s/step - accuracy: 0.5084 - loss: 1.1707 - val_accuracy: 0.0502 - val_loss: 2.6923\nEpoch 2/10\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1719637300.068099     231 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 834ms/step - accuracy: 0.7560 - loss: 0.6563 - val_accuracy: 1.8723e-04 - val_loss: 4.4970\nEpoch 3/10\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m287s\u001b[0m 846ms/step - accuracy: 0.8440 - loss: 0.4472 - val_accuracy: 0.0000e+00 - val_loss: 3.8359\nEpoch 4/10\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m293s\u001b[0m 860ms/step - accuracy: 0.8936 - loss: 0.3208 - val_accuracy: 0.4157 - val_loss: 2.1959\nEpoch 5/10\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 830ms/step - accuracy: 0.9219 - loss: 0.2355 - val_accuracy: 0.2949 - val_loss: 3.2739\nEpoch 6/10\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 831ms/step - accuracy: 0.9353 - loss: 0.1953 - val_accuracy: 0.0071 - val_loss: 3.3953\nEpoch 7/10\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 834ms/step - accuracy: 0.9466 - loss: 0.1597 - val_accuracy: 0.1101 - val_loss: 5.7145\nEpoch 8/10\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 828ms/step - accuracy: 0.9550 - loss: 0.1338 - val_accuracy: 0.0549 - val_loss: 5.3437\nEpoch 9/10\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m284s\u001b[0m 832ms/step - accuracy: 0.9630 - loss: 0.1193 - val_accuracy: 0.0427 - val_loss: 3.8039\nEpoch 10/10\n\u001b[1m334/334\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m279s\u001b[0m 819ms/step - accuracy: 0.9673 - loss: 0.1034 - val_accuracy: 0.4084 - val_loss: 2.7811\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# TESTING","metadata":{}},{"cell_type":"code","source":"test_csv_path = os.path.join(DATASET_DIR, f\"MotocycleDataset-Splits-{SPLITS_ID}-Test.csv\")\ntest_df = pd.read_csv(test_csv_path, header=None, names=[\"file_path\", \"class\"])\ntest_df[\"file_path\"] = test_df[\"file_path\"].apply(lambda x: os.path.join(DATASET_DIR, x))\ntest_df[\"class\"] = test_df[\"class\"].apply(lambda x: str(x))","metadata":{"execution":{"iopub.status.busy":"2024-06-29T05:44:14.996455Z","iopub.execute_input":"2024-06-29T05:44:14.996765Z","iopub.status.idle":"2024-06-29T05:44:15.042970Z","shell.execute_reply.started":"2024-06-29T05:44:14.996731Z","shell.execute_reply":"2024-06-29T05:44:15.042270Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_df = validate_images_multicore(test_df, num_processes=12)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T05:44:15.044086Z","iopub.execute_input":"2024-06-29T05:44:15.044403Z","iopub.status.idle":"2024-06-29T05:45:03.628987Z","shell.execute_reply.started":"2024-06-29T05:44:15.044356Z","shell.execute_reply":"2024-06-29T05:45:03.627741Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"code","source":"data_generator = ImageDataGenerator(rescale=1/255)\ndataframe_config = {\n    'dataframe': test_df,\n    'x_col': 'file_path',\n    'y_col': 'class',\n    'target_size': (HEIGHT, WIDTH),\n    'batch_size': BATCH_SIZE,\n    'class_mode': 'categorical',\n    'shuffle': True,\n    'seed': SEED,\n    'color_mode': 'rgb',\n}\ntest_generator = data_generator.flow_from_dataframe(**dataframe_config)","metadata":{"execution":{"iopub.status.busy":"2024-06-29T05:45:03.632046Z","iopub.execute_input":"2024-06-29T05:45:03.632429Z","iopub.status.idle":"2024-06-29T05:45:06.837261Z","shell.execute_reply.started":"2024-06-29T05:45:03.632370Z","shell.execute_reply":"2024-06-29T05:45:06.836356Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Found 6929 validated image filenames belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"loss, accuracy = model.evaluate(test_generator, steps=len(test_generator))\nprint(f\"Test Accuracy: {accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-29T05:53:21.851303Z","iopub.execute_input":"2024-06-29T05:53:21.852015Z","iopub.status.idle":"2024-06-29T05:54:33.214611Z","shell.execute_reply.started":"2024-06-29T05:53:21.851985Z","shell.execute_reply":"2024-06-29T05:54:33.213726Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 641ms/step - accuracy: 0.5684 - loss: 1.7599\nTest Accuracy: 0.57\n","output_type":"stream"}]}]}