{"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8789399,"sourceType":"datasetVersion","datasetId":5284217}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import hashlib\nimport numpy as np\nimport os\n#Thư viện os cung cấp các chức năng để tương tác với hệ điều hành\n#Nó cho phép thực hiện các thao tác như đọc, ghi tệp, thay đổi thư mục làm việc, và quản lý quy trình\nimport pandas as pd\nimport multiprocessing\n#hỗ trợ việc thực hiện các tác vụ song song bằng cách sử dụng nhiều tiến trình\n#Điều này rất hữu ích để tăng hiệu suất khi xử lý các tác vụ nặng về tính toán.\nfrom PIL import Image\n#PIL cung cấp các công cụ để mở, thao tác và lưu các tệp ảnh\n#Nó hỗ trợ nhiều định dạng ảnh và cung cấp các phương pháp để thực hiện các phép biến đổi cơ bản trên ảnh.\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n#cho phép tạo ra các lô dữ liệu hình ảnh với các phép biến đổi ảnh (data augmentation) như xoay, dịch chuyển, cắt, và thay đổi độ sáng\n#Điều này giúp tăng cường tính đa dạng của dữ liệu huấn luyện và giảm hiện tượng overfitting.\nfrom keras.optimizers import Adam\n#Adam là một thuật toán tối ưu hóa dựa trên gradient descent, thường được sử dụng để huấn luyện các mạng nơ-ron sâu\n#Nó kết hợp các ưu điểm của hai phương pháp AdaGrad và RMSProp, giúp mô hình hội tụ nhanh và hiệu quả hơn.\nimport tensorflow as tf\n#tf hỗ trợ tính toán bằng cách sử dụng GPU và TPU, và có thể được sử dụng cho cả nghiên cứu và ứng dụng sản phẩm.\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras import layers, models, optimizers, callbacks\n#Thư viện layers của Keras cung cấp các lớp xây dựng mạng nơ-ron (Dense,...). Những lớp này giúp định nghĩa kiến trúc của mạng nơ-ron một cách trực quan.\n#Thư viện models của Keras cung cấp các công cụ để định nghĩa và huấn luyện các mô hình mạng nơ-ron (Sequential,...)\n#Thư viện optimizers của Keras cung cấp các thuật toán tối ưu hóa như SGD, Adam, RMSprop, giúp điều chỉnh các tham số của mô hình để giảm thiểu hàm mất mát.\n#Thư viện callbacks của Keras cho phép bạn định nghĩa các hành động sẽ được thực hiện tại các điểm khác nhau trong quá trình huấn luyện (ví dụ như lưu trữ mô hình, giảm tốc độ học tập khi hiệu suất không cải thiện, dừng sớm khi mô hình không tiến bộ).","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:56:11.057103Z","iopub.execute_input":"2024-07-05T11:56:11.057673Z","iopub.status.idle":"2024-07-05T11:56:23.645717Z","shell.execute_reply.started":"2024-07-05T11:56:11.057640Z","shell.execute_reply":"2024-07-05T11:56:23.644768Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-05 11:56:13.736664: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-05 11:56:13.736763: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-05 11:56:13.868394: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"SPLITS_ID = 2","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:56:23.647588Z","iopub.execute_input":"2024-07-05T11:56:23.648222Z","iopub.status.idle":"2024-07-05T11:56:23.652434Z","shell.execute_reply.started":"2024-07-05T11:56:23.648189Z","shell.execute_reply":"2024-07-05T11:56:23.651580Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"DATASET_PATH = \"/kaggle/input/motocycledataset/Data\"","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:56:23.653595Z","iopub.execute_input":"2024-07-05T11:56:23.654115Z","iopub.status.idle":"2024-07-05T11:56:23.676753Z","shell.execute_reply.started":"2024-07-05T11:56:23.654091Z","shell.execute_reply":"2024-07-05T11:56:23.675920Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 64\n#\"Batch size\" là số lượng mẫu dữ liệu được đưa vào mô hình trong một lần huấn luyện (một batch)\nWIDTH = 224\nHEIGHT = 224\nSEED = 42\n#SEED khởi tạo bộ sinh số ngẫu nhiên\n#Khi sử dụng cùng một seed, bạn sẽ có được cùng một chuỗi số ngẫu nhiên mỗi lần chạy, giúp tái hiện được kết quả.","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:56:23.677979Z","iopub.execute_input":"2024-07-05T11:56:23.678561Z","iopub.status.idle":"2024-07-05T11:56:23.686415Z","shell.execute_reply.started":"2024-07-05T11:56:23.678530Z","shell.execute_reply":"2024-07-05T11:56:23.685671Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# DATA LOADING","metadata":{}},{"cell_type":"code","source":"#Tạo đường dẫn đến file train và test theo SPLITS_ID\ntrain_csv = os.path.join(DATASET_PATH, f\"MotocycleDataset-Splits-{SPLITS_ID}-Train.csv\")\ntest_csv = os.path.join(DATASET_PATH, f\"MotocycleDataset-Splits-{SPLITS_ID}-Test.csv\")\n\n#Đọc file\n#Tham số: header=None --> chỉ ra rằng tệp CSV không có dòng tiêu đề.\n#Tham số: names=[\"file_path\", \"class\"] --> gán tên cột đầu tiên là file_path và tên cột thứ hai là class.\ntrain_df = pd.read_csv(train_csv, header=None, names=[\"file_path\", \"class\"])\ntest_df = pd.read_csv(test_csv, header=None, names=[\"file_path\", \"class\"])\n\n#Cập nhật cột file_path trong DataFrame train_df, test_df bằng cách thêm đường dẫn cơ sở (DATASET_PATH) vào mỗi giá trị trong cột này\ntrain_df[\"file_path\"] = train_df[\"file_path\"].apply(lambda x: os.path.join(DATASET_PATH, x))\ntest_df[\"file_path\"] = test_df[\"file_path\"].apply(lambda x: os.path.join(DATASET_PATH, x))\n\n#Chuyển kiểu dữ liệua các gía trị trong cột class sang dạng string vì flow_from_dataframe cần đầu vào là kiểu string\ntrain_df[\"class\"] = train_df[\"class\"].astype(str)\ntest_df[\"class\"] = test_df[\"class\"].astype(str)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:56:23.688698Z","iopub.execute_input":"2024-07-05T11:56:23.688940Z","iopub.status.idle":"2024-07-05T11:56:23.867164Z","shell.execute_reply.started":"2024-07-05T11:56:23.688918Z","shell.execute_reply":"2024-07-05T11:56:23.866462Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# PREPROCESSING","metadata":{}},{"cell_type":"code","source":"image_set = set()\n#Tạo 1 set dùng để lưu trữ các giá trị hash của các mảng numpy đại diện cho ảnh. Điều này giúp phát hiện các ảnh trùng lặp.\n\ndef hash_numpy_array(arr):\n    '''\n    Mục đích: Tạo giá trị hash từ một mảng numpy để kiểm tra trùng lặp ảnh.\n    '''\n    arr_bytes = arr.tobytes()\n    #Chuyển đổi mảng numpy thành chuỗi bytes.\n    \n    hash_obj = hashlib.sha256(arr_bytes)\n    #Tạo đối tượng hash SHA-256 từ chuỗi bytes.\n    \n    hash_hex = hash_obj.hexdigest()\n    #Chuyển đổi đối tượng hash thành chuỗi hex.\n    \n    return hash_hex\n    #Trả về chuỗi hex của giá trị hash.\n\ndef validate_image(image_path, skip_duplicate):\n    '''\n    Mục đích: Xác thực một ảnh.\n    Cách hoạt động:\n        - Kiểm tra xem đường dẫn ảnh có tồn tại và là một tệp tin không.\n        - Mở ảnh và thay đổi kích thước.\n        - Nếu skip_duplicate là True, tính toán giá trị hash của ảnh và kiểm tra xem giá trị này đã có trong image_set chưa.\n            + Nếu đã có, trả về False.\n            + Nếu chưa, thêm giá trị hash vào image_set.\n        - Trả về True nếu ảnh hợp lệ.\n    '''\n    if not os.path.exists(image_path):\n        return False\n    if not os.path.isfile(image_path):\n        return False\n    try:\n        with Image.open(image_path) as img:\n            img.resize((WIDTH, HEIGHT))\n            if skip_duplicate:\n                hash_value = hash_numpy_array(np.array(img))\n                if hash_value in image_set:\n                    return False\n                else:\n                    image_set.add(hash_value)\n        return True\n\n    except Exception as e:\n        print(e)\n        return False\n        \ndef validate_images_multicore(df, num_processes, skip_duplicate=False):\n    '''\n    Mục đích: Xác thực các ảnh trong DataFrame bằng cách sử dụng nhiều tiến trình.\n    Cách hoạt động:\n        - multiprocessing.Pool(num_processes): Tạo một pool với số lượng tiến trình được chỉ định bởi num_processes.\n        - pool.starmap(validate_image, \n                       zip(df[\"file_path\"], \n                       [skip_duplicate] * len(df))\n                       ): Phân chia công việc xác thực ảnh giữa các tiến trình.\n        - zip(df[\"file_path\"],\n              [skip_duplicate] * len(df)\n              ): Kết hợp từng đường dẫn ảnh với giá trị skip_duplicate để truyền vào hàm validate_image.\n        - return df[results]: Trả về DataFrame chỉ chứa các hàng mà ảnh đã được xác thực hợp lệ.\n    '''\n    with multiprocessing.Pool(num_processes) as pool:\n        results = pool.starmap(\n            validate_image, \n            zip(df[\"file_path\"], [skip_duplicate] * len(df))\n        )\n    return df[results]  ","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:56:23.868140Z","iopub.execute_input":"2024-07-05T11:56:23.868420Z","iopub.status.idle":"2024-07-05T11:56:23.879190Z","shell.execute_reply.started":"2024-07-05T11:56:23.868396Z","shell.execute_reply":"2024-07-05T11:56:23.878291Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"train_df = validate_images_multicore(train_df, num_processes=16, skip_duplicate=True)\n#sử dụng hàm validate_images_multicore để kiểm tra và xác thực các tệp ảnh trong DataFrame train_df bằng cách sử dụng 16 tiến trình.\n\n#train_df là DataFrame chứa thông tin về các tệp ảnh cần xác thực\n\n#num_processes chỉ định số lượng tiến trình sẽ được sử dụng trong pool\n#Trong trường hợp này, 16 tiến trình sẽ được sử dụng\n#Sử dụng nhiều tiến trình giúp phân chia công việc và xử lý nhiều tệp ảnh đồng thời, tăng tốc độ xử lý.\n\n#Tham số skip_duplicate chỉ định liệu có bỏ qua các ảnh trùng lặp hay không\n#Trong trường hợp này, skip_duplicate được đặt là False, nghĩa là hàm sẽ không kiểm tra và bỏ qua các ảnh trùng lặp.","metadata":{"execution":{"iopub.status.busy":"2024-07-05T11:56:23.880385Z","iopub.execute_input":"2024-07-05T11:56:23.880691Z","iopub.status.idle":"2024-07-05T12:01:24.866622Z","shell.execute_reply.started":"2024-07-05T11:56:23.880662Z","shell.execute_reply":"2024-07-05T12:01:24.865410Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"image file is truncated (8 bytes not processed)\ncannot identify image file '/kaggle/input/motocycledataset/Data/VinFast/22520968-22520996-22520999-22520929-22521373.VinFast.277.jpg'\ncannot identify image file '/kaggle/input/motocycledataset/Data/VinFast/22520968-22520996-22520999-22520929-22521373.VinFast.311.jpg'\ncannot identify image file '/kaggle/input/motocycledataset/Data/VinFast/22520968-22520996-22520999-22520929-22521373.VinFast.323.jpg'\ncannot identify image file '/kaggle/input/motocycledataset/Data/Others/22520968-22520996-22520999-22520929-22521373.Others.567.jpg'\ncannot identify image file '/kaggle/input/motocycledataset/Data/Others/22520968-22520996-22520999-22520929-22521373.Others.568.jpg'\n","output_type":"stream"}]},{"cell_type":"code","source":"image_set = set()\n#Gán biến image_set bằng một tập hợp mới, chuẩn bị cho việc kiểm tra ảnh trùng trong tập test_df","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:01:24.868031Z","iopub.execute_input":"2024-07-05T12:01:24.868308Z","iopub.status.idle":"2024-07-05T12:01:24.873029Z","shell.execute_reply.started":"2024-07-05T12:01:24.868281Z","shell.execute_reply":"2024-07-05T12:01:24.872047Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_df = validate_images_multicore(test_df, num_processes=16)\n#Tham số skip_duplicate có giá trị mặc định là False.\n#Điều này có nghĩa là hàm validate_image sẽ không thực hiện việc kiểm tra và bỏ qua các ảnh trùng lặp\n#Do đó, tất cả các ảnh trong test_df sẽ được xử lý mà không quan tâm đến việc kiểm tra tính duy nhất của chúng dựa trên giá trị hash.","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:01:24.874226Z","iopub.execute_input":"2024-07-05T12:01:24.874509Z","iopub.status.idle":"2024-07-05T12:02:12.524154Z","shell.execute_reply.started":"2024-07-05T12:01:24.874485Z","shell.execute_reply":"2024-07-05T12:02:12.522915Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"},{"name":"stdout","text":"cannot identify image file '/kaggle/input/motocycledataset/Data/VinFast/22520968-22520996-22520999-22520929-22521373.VinFast.313.jpg'\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  self.pid = os.fork()\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# TRAINING","metadata":{}},{"cell_type":"code","source":"train_data_generator = ImageDataGenerator(\n    rescale=1/255,\n    validation_split=0.2,\n)\n#ImageDataGenerator:\n#Tham số: rescale=1/255\n    #Ban đầu: Giá trị của mỗi pixel trong một ảnh thường nằm trong khoảng [0, 255]\n    #Sau khi chuẩn hóa: Bằng cách chia giá trị của mỗi pixel cho 255, ta thu được giá trị mới nằm trong khoảng [0, 1]\n    #Mục đích chuẩn hóa: Thuận tiện tính toán, tăng tốc độ học.\n#Tham số: validation_split=0.2\n    #20% dữ liệu sẽ được sử dụng cho validation set, còn lại sẽ là training set.\n    \ntest_data_generator = ImageDataGenerator(rescale=1/255)\n\ndataframe_config = {\n    'x_col': 'file_path', \n    'y_col': 'class',\n    'target_size': (HEIGHT, WIDTH),\n    'batch_size': BATCH_SIZE,\n    'class_mode': 'categorical',\n    'shuffle': True,\n    'seed': SEED,\n    'color_mode': 'rgb',\n}\n#x_col và y_col: Chỉ định tên cột trong DataFrame train_df và test_df lần lượt là \"file_path\" và \"class\"\n#Cột \"file_path\" chứa đường dẫn tới các tệp ảnh, \"class\" chứa nhãn lớp của từng ảnh.\n\n#target_size: Kích thước mà ảnh sẽ được chuyển đổi thành trước khi được đưa vào mô hình (HEIGHT, WIDTH).\n\n#batch_size: Số lượng ảnh được tạo thành một batch để đưa vào mô hình trong mỗi lần huấn luyện.\n\n#class_mode='categorical': Loại dữ liệu nhãn, ở đây là các nhãn được mã hóa one-hot vector.\n\n#shuffle=True: Xáo trộn dữ liệu trong quá trình huấn luyện để đảm bảo mô hình học được tốt hơn.\n\n#seed: Đặt seed để đảm bảo tính nhất quán của việc xáo trộn dữ liệu.\n\n#color_mode='rgb': Chế độ màu của ảnh, ở đây là ảnh màu RGB.\n\ntrain_generator = train_data_generator.flow_from_dataframe(train_df, **dataframe_config, subset='training')\nval_generator = train_data_generator.flow_from_dataframe(train_df, **dataframe_config, subset='validation')\ntest_generator = train_data_generator.flow_from_dataframe(test_df, **dataframe_config)\n\n#flow_from_dataframe: Phương thức này tạo ra một đối tượng dữ liệu sinh ra các batch từ DataFrame, thích hợp để sử dụng trong mô hình học sâu.\n#subset='training' và subset='validation': Chỉ định rằng train_generator và val_generator chỉ nên sinh ra dữ liệu từ phần huấn luyện và validation của train_df, được xác định bởi validation_split trong train_data_generator.","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:02:12.526047Z","iopub.execute_input":"2024-07-05T12:02:12.526754Z","iopub.status.idle":"2024-07-05T12:02:42.689488Z","shell.execute_reply.started":"2024-07-05T12:02:12.526716Z","shell.execute_reply":"2024-07-05T12:02:42.688547Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Found 21459 validated image filenames belonging to 5 classes.\nFound 5364 validated image filenames belonging to 5 classes.\nFound 6916 validated image filenames belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"base_model = ResNet50(\n    include_top=False,\n    weights='imagenet',\n    input_shape=(224, 224, 3)\n)\n\nmodel = models.Sequential()\nmodel.add(base_model)\n\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(128, activation='relu'))\nmodel.add(layers.Dense(64, activation='relu'))\nmodel.add(layers.Dense(5, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:02:42.690686Z","iopub.execute_input":"2024-07-05T12:02:42.691024Z","iopub.status.idle":"2024-07-05T12:02:45.613309Z","shell.execute_reply.started":"2024-07-05T12:02:42.690996Z","shell.execute_reply":"2024-07-05T12:02:45.612550Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"learning_rate = 0.0001\nepochs = 15\n","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:02:45.614424Z","iopub.execute_input":"2024-07-05T12:02:45.614716Z","iopub.status.idle":"2024-07-05T12:02:45.618787Z","shell.execute_reply.started":"2024-07-05T12:02:45.614690Z","shell.execute_reply":"2024-07-05T12:02:45.617846Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=Adam(learning_rate=learning_rate),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:02:45.620045Z","iopub.execute_input":"2024-07-05T12:02:45.620731Z","iopub.status.idle":"2024-07-05T12:02:45.639842Z","shell.execute_reply.started":"2024-07-05T12:02:45.620698Z","shell.execute_reply":"2024-07-05T12:02:45.638893Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"history = model.fit(\n    train_generator,\n    epochs=epochs,\n    validation_data=val_generator\n)\n\n#train_generator: Đối số đầu tiên train_generator cung cấp dữ liệu huấn luyện cho mô hình.\n\n#epochs=epochs: Đối số epochs chỉ định số lượng lượt huấn luyện (epoch) mà mô hình sẽ được huấn luyện trên train_generator\n#Mỗi epoch tương đương với việc đưa toàn bộ dữ liệu qua mô hình một lần.\n\n#validation_data=val_generator: Đối số validation_data cho phép cung cấp dữ liệu validation để đánh giá hiệu suất của mô hình sau mỗi epoch.","metadata":{"execution":{"iopub.status.busy":"2024-07-05T12:02:45.642994Z","iopub.execute_input":"2024-07-05T12:02:45.643233Z","iopub.status.idle":"2024-07-05T13:15:50.228512Z","shell.execute_reply.started":"2024-07-05T12:02:45.643213Z","shell.execute_reply":"2024-07-05T13:15:50.227533Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n/opt/conda/lib/python3.10/site-packages/PIL/Image.py:992: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n  warnings.warn(\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1720181061.420647     184 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nW0000 00:00:1720181061.513939     184 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m208/336\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m1:48\u001b[0m 849ms/step - accuracy: 0.3980 - loss: 1.3846","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720181237.596402     184 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766ms/step - accuracy: 0.4493 - loss: 1.2839","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720181325.094198     184 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m424s\u001b[0m 982ms/step - accuracy: 0.4496 - loss: 1.2832 - val_accuracy: 0.0000e+00 - val_loss: 2.6959\nEpoch 2/15\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720181391.009550     182 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m281s\u001b[0m 820ms/step - accuracy: 0.7770 - loss: 0.6051 - val_accuracy: 0.0362 - val_loss: 3.6871\nEpoch 3/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 828ms/step - accuracy: 0.8938 - loss: 0.3187 - val_accuracy: 0.3693 - val_loss: 2.2623\nEpoch 4/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 819ms/step - accuracy: 0.9392 - loss: 0.1925 - val_accuracy: 0.5194 - val_loss: 2.5083\nEpoch 5/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 824ms/step - accuracy: 0.9611 - loss: 0.1259 - val_accuracy: 0.4193 - val_loss: 2.9346\nEpoch 6/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m276s\u001b[0m 808ms/step - accuracy: 0.9712 - loss: 0.0974 - val_accuracy: 0.5468 - val_loss: 2.3131\nEpoch 7/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m283s\u001b[0m 828ms/step - accuracy: 0.9754 - loss: 0.0841 - val_accuracy: 0.3686 - val_loss: 3.5005\nEpoch 8/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 810ms/step - accuracy: 0.9794 - loss: 0.0658 - val_accuracy: 0.4334 - val_loss: 3.3368\nEpoch 9/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 812ms/step - accuracy: 0.9809 - loss: 0.0602 - val_accuracy: 0.4085 - val_loss: 3.3468\nEpoch 10/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 813ms/step - accuracy: 0.9790 - loss: 0.0652 - val_accuracy: 0.2968 - val_loss: 4.6949\nEpoch 11/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m278s\u001b[0m 813ms/step - accuracy: 0.9846 - loss: 0.0468 - val_accuracy: 0.4390 - val_loss: 3.2376\nEpoch 12/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 820ms/step - accuracy: 0.9809 - loss: 0.0621 - val_accuracy: 0.4042 - val_loss: 3.7571\nEpoch 13/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m282s\u001b[0m 827ms/step - accuracy: 0.9836 - loss: 0.0504 - val_accuracy: 0.5157 - val_loss: 2.9617\nEpoch 14/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m277s\u001b[0m 810ms/step - accuracy: 0.9834 - loss: 0.0522 - val_accuracy: 0.4182 - val_loss: 3.3908\nEpoch 15/15\n\u001b[1m336/336\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m280s\u001b[0m 819ms/step - accuracy: 0.9882 - loss: 0.0363 - val_accuracy: 0.3015 - val_loss: 5.1848\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# TESTING","metadata":{}},{"cell_type":"code","source":"loss, accuracy = model.evaluate(test_generator, steps=len(test_generator))\nprint(f\"Test Accuracy: {accuracy:.6f}\")\n\n#model.evaluate(test_generator, steps=len(test_generator)): Đoạn này thực hiện việc đánh giá mô hình (model) bằng cách sử dụng dữ liệu từ test_generator\n#Đối số steps=len(test_generator) cho biết số lượng bước (batch) mà generator sẽ tạo ra để đánh giá\n#Mỗi bước sẽ tạo ra một batch dữ liệu để đưa vào mô hình để tính toán loss và accuracy.","metadata":{"execution":{"iopub.status.busy":"2024-07-05T13:15:50.230014Z","iopub.execute_input":"2024-07-05T13:15:50.230398Z","iopub.status.idle":"2024-07-05T13:17:06.954254Z","shell.execute_reply.started":"2024-07-05T13:15:50.230363Z","shell.execute_reply":"2024-07-05T13:17:06.953394Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"\u001b[1m109/109\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 691ms/step - accuracy: 0.6838 - loss: 1.9316\nTest Accuracy: 0.685656\n","output_type":"stream"},{"name":"stderr","text":"W0000 00:00:1720185426.923600     184 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n","output_type":"stream"}]},{"cell_type":"markdown","source":"----------------------------------------------------","metadata":{}},{"cell_type":"code","source":"# test_df = validate_images_multicore(test_df, num_processes=12)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T13:17:06.955670Z","iopub.execute_input":"2024-07-05T13:17:06.955969Z","iopub.status.idle":"2024-07-05T13:17:06.960007Z","shell.execute_reply.started":"2024-07-05T13:17:06.955942Z","shell.execute_reply":"2024-07-05T13:17:06.959081Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# data_generator = ImageDataGenerator(rescale=1/255)\n# dataframe_config = {\n#     'dataframe': test_df,\n#     'x_col': 'file_path',\n#     'y_col': 'class',\n#     'target_size': (HEIGHT, WIDTH),\n#     'batch_size': BATCH_SIZE,\n#     'class_mode': 'categorical',\n#     'shuffle': True,\n#     'seed': SEED,\n#     'color_mode': 'rgb',\n# }\n# test_generator = data_generator.flow_from_dataframe(**dataframe_config)","metadata":{"execution":{"iopub.status.busy":"2024-07-05T13:17:06.961280Z","iopub.execute_input":"2024-07-05T13:17:06.962053Z","iopub.status.idle":"2024-07-05T13:17:06.970328Z","shell.execute_reply.started":"2024-07-05T13:17:06.962019Z","shell.execute_reply":"2024-07-05T13:17:06.969569Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# loss, accuracy = model.evaluate(test_generator, steps=len(test_generator))\n# print(f\"Test Accuracy: {accuracy:.2f}\")","metadata":{"execution":{"iopub.status.busy":"2024-07-05T13:17:06.971404Z","iopub.execute_input":"2024-07-05T13:17:06.971673Z","iopub.status.idle":"2024-07-05T13:17:06.980852Z","shell.execute_reply.started":"2024-07-05T13:17:06.971650Z","shell.execute_reply":"2024-07-05T13:17:06.979999Z"},"trusted":true},"execution_count":18,"outputs":[]}]}